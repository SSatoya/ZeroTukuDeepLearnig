{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527a653e",
   "metadata": {},
   "source": [
    "# 第8章 ディープラーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0d52c",
   "metadata": {},
   "source": [
    "# ネットワークをより深く"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b64be",
   "metadata": {},
   "source": [
    "## よりディープなネットワークへ\n",
    "> **ディープラーニング**<br>\n",
    "> 層を深くしたディープなニューラルネットワーク\n",
    "- より層が深いネットワークを構築する\n",
    "    ```\n",
    "    入力画像 \n",
    "    --> Conv→ReLU→Conv→ReLU→Pool \n",
    "    --> Conv→ReLU→Conv→ReLU→Pool \n",
    "    --> Conv→ReLU→Conv→ReLU→Pool\n",
    "    --> Affine→ReLU→Dropout\n",
    "    --> Affine→Dropout→Softmax\n",
    "    -->\n",
    "    ```\n",
    "    - 畳み込み層はすべて3x3も小さなフィルター\n",
    "    - 層が深くなるにつれてチャンネル数が大きくなる\n",
    "        - 畳み込み層のチャンネルは、前層から順に`16, 16, 32, 32, 64, 64`と増加\n",
    "    - プーリング層をはさむことで中間データの空間サイズを徐々に小さくする\n",
    "    - 後段の全結合層は`Dropout`レイヤを使用\n",
    "\n",
    "    - ネットワークの特徴\n",
    "        - `3x3`の小さなフィルターによる畳み込み層\n",
    "        - 活性化関数：`ReLU`\n",
    "        - 全結合層の後に`Dropout`レイヤを使用\n",
    "        - `Adam`による最適化\n",
    "        - 重みの初期値として`「Heの初期値」`を使用\n",
    "- ディープラーニングのは、これまでにやった多くの技術を使用\n",
    "    - 認識制度：99.38%\n",
    "    - 誤認識率：0.62%<br>とめちゃいい性能になる！（らしい）\n",
    "    - 誤認識してしまった画像は、人が見ても判断が難しい画像だった"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610115b",
   "metadata": {},
   "source": [
    "## さらに認識制度を高めるには？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed655e39",
   "metadata": {},
   "source": [
    "- [この記事](https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354)には、様々なデータセットを対象に論文が発表されており、手法の認識制度がランキング形式で掲載\n",
    "- 2025年6月時点では、MNISTデータセットに対する最高の認識精度は`誤認識率0.21%`(99.79%)でその手法もCNNベース\n",
    "    - これはあまりディープなネットワークではないらしい\n",
    "    - 手書き文字の認識は単純でそこまで層を深くしても恩恵が少ない\n",
    "- ランキング上位の手法\n",
    "    - アンサンブル学習\n",
    "    - 学習係数の減衰（learning rate decay）\n",
    "    - **Data Augmentation**（データ拡張）\n",
    "        - 簡単な手法であり、認識精度を向上させる上で特に有効な手段\n",
    "- Data Agumentationは、訓練画像をアルゴリズムによって「人工的」に拡張\n",
    "    - 入力画像に対して...\n",
    "        - 回転\n",
    "        - 縦横方向移動\n",
    "        - 画像の中から一部を切り出す「**crop処理**」\n",
    "        - 左右をひっくり返す「**flip処理**」\n",
    "        - 輝度などの見た目の変化\n",
    "        - 拡大・縮小などのスケール変化\n",
    "        <br>など微小な変化を与え、**画像枚数を増やす**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36153f6f",
   "metadata": {},
   "source": [
    "## 層を深くすることのモチベーション\n",
    "- 「層を深くすること」の重要性\n",
    "    - 論理的にそれほど多くのことがわかってない\n",
    "    - 傾向的に...\n",
    "        - 大規模画像認識のコンペでは、層が深い程認識精度が高い傾向がある\n",
    "- 層が深くすることの利点\n",
    "    - **ネットワークのパラメータ数を少なくできる**\n",
    "        - 層を深くしたネットワークは、層を深くしなかった場合に比べて、より少ないパラメータ数で同レベル（それ以上）の表現力を達成\n",
    "        - 図はp247参照\n",
    "        - Ex)`5x5`のフィルターからなる畳み込み層\n",
    "            - 出力ノード一つあたり、入力データの`5x5`の領域から計算\n",
    "        - Ex)`3x3`の畳み込み層を２回繰り返す\n",
    "            - 出力ノード１つあたり、中間データでは`3x3`の領域から計算\n",
    "            - 中間データの`3x3`は、入力データの`5x5`の領域に対応している\n",
    "        - 例から、`5x5`の畳み込み演算は、`3x3`の畳み込み演算を2回行うことでカバーできる\n",
    "            - パラメータ数\n",
    "                - `5x5`： $5 × 5 = 25$\n",
    "                - `3x3`： $2 × (3 × 3) = 18$ (3 x 3の畳み込みを2回繰り返す)<br>\n",
    "                と、パラメータ数を少なくできる！！\n",
    "    - **受容野**を広くカバーできる\n",
    "        > **受容野**<br>\n",
    "        > ニューロンの変化を生じさせる局所的な空間領域\n",
    "    - 表現力の向上\n",
    "        - ReLUなどの活性化関数が畳み込み層の間に挟まることで、ネットワークの表現力が向上\n",
    "        - 活性化関数によってネットワークが「非線形」の力が加わるから\n",
    "    - 学習の効率性\n",
    "        - 層を深くすることで学習データを少なくでき、高速に学習が行える\n",
    "        - これは、CNNにおいて層が深くなるほど「より複雑で抽象化された情報を抽出する」ことに起因する\n",
    "        - Ex) 「犬」を認識する\n",
    "            - **層が浅い**ネットワークの場合\n",
    "                - 畳み込み層は「犬」の特徴の多くを１度に\"理解\"する必要がある\n",
    "                - 「犬」には様々な種類と、撮影される環境による見え方の違いがある\n",
    "                - 様々な条件の「犬」を認識するためには、**多くのバリエーションにとんだ学習データが必要**\n",
    "                    - 多くの学習時間を要する\n",
    "            - **層が深い**ネットワークの場合\n",
    "                - **学習するべき問題を階層的に分解**することが可能\n",
    "                    - より単純な問題として取り組むことができる\n",
    "                    - 最初の層はエッジ、次はテクスチャ...など少ない学習データで効率よく学習できる\n",
    "    - 階層的に情報を渡していくことができる\n",
    "        - エッジ抽出後の層は、エッジ情報が使用できるのでより高度なパターンを学習できる\n",
    "        - 各層が学習するべき問題を「簡単な問題」へと分解可能！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851db008",
   "metadata": {},
   "source": [
    "# ディープラーニングの小歴史\n",
    "## ImageNet\n",
    "- 100万枚を超える画像データセット\n",
    "    - 画像には、ラベル（クラス名）が紐づけ\n",
    "- ILSVRC(ImageNet Large Scale Cisual Recognition Challenge)というコンペティションに使用\n",
    "- 2012年に**AlexNet**ができてきてから、誤認識率が低いのはディープラーニングを使用したもの\n",
    "- 有名なネットワークの登場\n",
    "    - *VGG*\n",
    "    - *GoogLeNet*\n",
    "    - *ResNet*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b066bef",
   "metadata": {},
   "source": [
    "## VGG\n",
    "- 畳み込み層とプーリング層から構成される基本的なCNN\n",
    "- 重みのある層を全部で16層または19層まで重ねてディープにしている\n",
    "- 特徴：\n",
    "    - `3x3`の小さなフィルターによる畳み込み層を連続で行う\n",
    "    - 畳み込み層を2~4回連続で行い、その後プーリング層でサイズを半分にする処理を繰り返し行う\n",
    "    - 最後に全結合層を経由して結果を出力\n",
    "- シンプル構成で、応用性が高い！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e8152d",
   "metadata": {},
   "source": [
    "## GoogLeNet\n",
    "- GoogLeNetのネットワーク構成[詳しくはこちら](https://dx-consultant-fast-evolving.com/googlenet/)<br>\n",
    "    ![ネットワーク構成](http://dx-consultant-fast-evolving.com/wp-content/uploads/2022/12/GoogleNet%E3%81%AE%E5%85%A8%E4%BD%93%E5%83%8F.jpg)\n",
    "    - 左から224x224の画像を入力し、畳み込み層やプーリング層を経て右に流れる\n",
    "- 特徴\n",
    "    - 層が多い\n",
    "        - 立ての深さだけでなく横にも深さ（広がり）がある\n",
    "        - 幅の存在\n",
    "            - **インセプション構造**\n",
    "                ![インセプションモジュール](http://dx-consultant-fast-evolving.com/wp-content/uploads/2022/12/inception%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB.jpg)\n",
    "                - サイズの異なるフィルターとプーリング層を複数適用し、結果を結合する\n",
    "                - このインセプション構想を１つの構成要素として使用（図の途中で複雑に見えるのはこれのせい）\n",
    "    - `1x1`の畳み込み層\n",
    "        - この演算により、チャンネル方向にサイズを減らすことで、パラメータの削減や処理の高速化に貢献"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361f5ab",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "- Microsoftによって開発されたネットワーク\n",
    "- 特徴：\n",
    "    - これまで以上に層を深くできるような\"仕掛け\"がある\n",
    "        - 課題として、層を深くしすぎても学習がうまくいかず最終的な性能が劣る可能性があった\n",
    "        - 解決方法として、「**ステップ構造**」（ショートカットやバイパス）を導入\n",
    "            - 層を深くすることに比例して、性能を向上できる\n",
    "- **ステップ構造**<br>\n",
    "    ![ステップ構造](https://www.bigdata-navi.com/aidrops/wp-content/uploads/2020/03/3-300x266.png)\n",
    "    - 入力データを畳み込みを行わず、出力層に合算する構造\n",
    "    - 逆伝播時に、ステップ構造による信号の減衰が抑えられるから\n",
    "        - とくに演算するわけではないので、逆伝播もそのまま下流へ流す\n",
    "        - 勾配が小さくなったり大きくなったりする心配がなく、前層の「意味のある勾配」が伝わっていく\n",
    "        - 層が深まることで発生する、**勾配消失問題**を軽減できる\n",
    "- 構造\n",
    "    - VGGのネットワークをベースとして、ステップ構造を取り入れ、層を深くしていく\n",
    "    - 畳み込み層を2層おきにステップしてつなぎ、層を深くしていく\n",
    "    - 150層以上に深くしても認識精度は向上し続けることがわかっている\n",
    "> **転移学習**<br>\n",
    "> 学習した重みデータを有効活用すること<br>\n",
    "> 学習済みの重みを別のニューラルネットワークにコピーして、再学習を行う<br>\n",
    "> 手元にあるデータセットが少ない場合に有効な手法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc9f75",
   "metadata": {},
   "source": [
    "# ディープラーニングの高速化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7245f507",
   "metadata": {},
   "source": [
    "## 取り組むべき問題\n",
    "- AlexNetで各層に費やされる時間を比較\n",
    "    - GPU\n",
    "        - 畳み込み層の処理時間：全体の95%\n",
    "    - CPU\n",
    "        - 畳み込み層の処理時間：全体の89%\n",
    "    - 全体的に**畳み込み層で多くの時間が費やされる**！！\n",
    "        - 積和演算が原因？\n",
    "        - 大量の積和演算をいかに効率欲計算するかが鍵となる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69efa73b",
   "metadata": {},
   "source": [
    "## GPUによる高速化\n",
    "- GPUは**並列的な数値演算を高速に行うことができる**\n",
    "    - これにより、大量の積和演算を並列的に処理し、高速化することができる\n",
    "- CPUで40日以上かかる処理を6日に短縮可能\n",
    "- 基本的にはNvidaiのGPUから恩恵を受けれる\n",
    "    - Nvidaiが提供するCUDAというGPUコンピューティング向けの統合開発環境がディープラーニングのフレームワークで使用されている"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc9517",
   "metadata": {},
   "source": [
    "## 分散学習\n",
    "- GPUの使用により、演算は高速化できる\n",
    "- 層の深いネットワークは学習にめちゃくちゃ時間はかかる...\n",
    "- 1回の学習に要する時間をできるだけ小さくすることが大切\n",
    "    - **分散学習**が重要になってくる\n",
    "- より高速化を目指して\n",
    "    - 複数のGPUや複数台のマシンで分散して計算を行う\n",
    "    - この分散学習をサポートしているものはいくつかある\n",
    "        - Google：TensorFlow\n",
    "        - Microsoft：CNTK\n",
    "    - 使用するGPUが増える程、学習速度も向上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a5565",
   "metadata": {},
   "source": [
    "## 演算精度のビット削減\n",
    "- メモリ容量やバス帯域などもボトルネックに...!\n",
    "    - メモリ：\n",
    "        - 大量の重みパラメータや中間データがメモリに収めることを考慮\n",
    "    - バス帯域:\n",
    "        - GPUもしくはCPUのバスを流れるデータ数が増加して制限を超えるなど\n",
    "- ネットワークに流れるデータのビット数はできるだけ小さくしたほうが良い\n",
    "    - コンピュータ上では数値を多くのビットを使うことで、誤差なく表現可能\n",
    "    - その分計算の処理こすとやメモリ使用量が増大・バス帯域に負荷\n",
    "- ディープラーニングでは**そこまで数値精度を必要としない**\n",
    "    - ニューラルネットワークでは、ロバスト性（依存性）が少ないことに起因する\n",
    "    - ネットワークに流れるデータを劣化させても出力結果への影響は少ない\n",
    "    - 16ビットの**半精度浮動小数点**でも問題なく学習できる\n",
    "\n",
    "- ビット数削減の研究\n",
    "    - Binarized Neural Networks\n",
    "        - 重みや中間データを1bitで表現"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c92d6",
   "metadata": {},
   "source": [
    "# ディープラーニングの実用例\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ccc290",
   "metadata": {},
   "source": [
    "## 物体検出\n",
    "- 画像の中から物体の位置を特定を含めてクラス分類を行う問題\n",
    "    - 物体認識よりもムズイ\n",
    "    - 画像中から、クラスの位置まで特定する必要がある\n",
    "    - 物体は複数個存在する可能性\n",
    "- 物体検出は、CNNベースの手法がいくつか提案されている\n",
    "    - ディープラーニングが有効になる\n",
    "- 有名な手法\n",
    "    - **R-CNN**\n",
    "        - 処理の流れ\n",
    "            1. Input Image(画像を入力)\n",
    "            2. Extract region proposals(~2k)（**候補領域抽出**）\n",
    "            3. Compute CNN features（CNN特徴の計算）\n",
    "            4. Classify regions（クラス分類）\n",
    "        - 候補領域抽出とCNN特徴の計算\n",
    "            - 最初にオブジェクトらしい領域を探し出す（Selective Serch）\n",
    "            - 領域を抽出して、CNNを適用してクラス分類\n",
    "        - 画像を正方形に変形したり、分類の際にSVM(サポートベクターマシン)を使ったりと、実際の処理フローは少々複雑\n",
    "            - 大きな目で見れば、重要なのは候補領域抽出とCNNの適用部分\n",
    "            - 近年では、候補領域抽出もCNNによって行う`Faster R-CNN`という手法も提案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f192f8",
   "metadata": {},
   "source": [
    "## セグメンテーション\n",
    "- 画像に対してピクセルレベルでクラス分類を行う問題\n",
    "- ピクセル単位でオブジェクトごとに色付けされた教師データを使用して学習\n",
    "- 推論時は、入力画像の**すべてのピクセルに対してクラス分類**を行う\n",
    "    - 今まで：画像全体に対してクラス分類\n",
    "    - pixcelレベルに落とし込むには？\n",
    "- 特徴\n",
    "    - ピクセルごとに推論処理を行う\n",
    "        - めちゃくちゃ時間かかりそう\n",
    "        - 改善のために`FCN(Fully Convolutional Network)`という手法が提案\n",
    "            - 一回のforward処理ですべてのピクセルにクラス分類を行う\n",
    "            - FCN = 「すべてが畳み込み層から構築されるネットワーク」\n",
    "            - FCNでは、「全結合層」を「同じ働きをする畳み込み層」に置き換える\n",
    "            - 空間ボリュームは保たれたまま最後の出力まで処理\n",
    "    - 最後に空間サイズを拡大する処理\n",
    "        - 小さくなった中間データを入力がオズのサイズと同じ大木さんで拡大（バイナリ拡大）\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f723bc",
   "metadata": {},
   "source": [
    "## 画像キャプション生成\n",
    "- 自然言語処理とコンピュータビジョンの融合\n",
    "- 画像を与えると画像を説明する文章の生成\n",
    "- 代表的な手法\n",
    "    - `NIC(Neural Image Caption)`\n",
    "        - ディープなCNNと自然言語処理のための`RNN（Recurrent Neural Network）`から構成\n",
    "        > **RNN**<br>\n",
    "        > 再帰的なつながりをもつネットワークであり、自然言語や時系列データなど連続性のあるデータを取り扱える\n",
    "        - 流れ \n",
    "            - CNNによって特徴を抽出\n",
    "            - 抽出した特徴をRNNに渡す\n",
    "            - RNNは特徴を初期値として、テキストを\"再帰的\"に生成\n",
    "> **マルチモーダル**<br>\n",
    "> 画像と自然言語といったように、**複数の種類の情報を組み合わせて処理すること**\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d667a01",
   "metadata": {},
   "source": [
    "# ディープラーニングの未来"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3bf75f",
   "metadata": {},
   "source": [
    "## 画像スタイル変換\n",
    "- ディープラーニングを使って、アーティストのような絵を\"描かせる\"研究\n",
    "- ２つの画像を入力して新たな画像を生成する\n",
    "    - コンテンツ画像：スタイルを適用したい画像\n",
    "    - スタイル画像：描画のスタイルを入力（ゴッホの絵など）\n",
    "- 技術部分（簡単に）\n",
    "    - ネットワークの中間データが「コンテンツ画像」の中間データに近づくように学習\n",
    "    - 入力画像をコンテンツ画像の形状に合わせることがきでうｒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b612b69a",
   "metadata": {},
   "source": [
    "## 画像生成\n",
    "- なんの画像も入力せず新しい画像を生成する\n",
    "    - (学習時には、大量の画像を使うが、生成時にはなんの画像も必要としない)\n",
    "- 代表的な手法：`DCGAN（Deep Convolutional Generative Adversarial Network）`\n",
    "    - 技術：\n",
    "        - Generator（生成者）というニューラルネットワーク\n",
    "            - 本物にそっくりの画像を生成\n",
    "        - Discriminator（識別者）というニューラルネットワーク\n",
    "            - Generatorが生成した画像が本物なのか生成したものなかを判別\n",
    "        - 両者を競い会うように成長させていくのが`GAN(Generative Adversarial Network)`と呼ばれる技術\n",
    "\n",
    "> **教師あり学習と教師なし学習**<br>\n",
    "> - 教師あり学習<br>\n",
    "> 画像データと教師ラベルが対になって与えられたデータセットを利用（手書き文字認識など）\n",
    "> - 教師なし学習<br>\n",
    "> 単に大量のデータの集合（画像のみなど）だけが与えられる（Deep Belief Network, Deep Blotzmann Machineなど）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7874dfe",
   "metadata": {},
   "source": [
    "## 自動運転\n",
    "- 人間の変わりにコンピュータが自動車を運転\n",
    "- 使用技術\n",
    "    - パスプラン（path plan）：通行ルート決め\n",
    "    - センシング技術：カメラやレーザーなど\n",
    "- 周囲環境の正しい認識が重要\n",
    "    - 様々な環境にロバストに走行領域を正しく認識できるようになれば、実現可能になるかも\n",
    "    - `SegNet`とよばれうCNNベースのネットワークは、高精度に走行環境を認識"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc13dd8",
   "metadata": {},
   "source": [
    "## Deep Q-Network（強化学習）\n",
    "> **強化学習**<br>\n",
    "> コンピュータにも試行錯誤の過程から自律的に学習させようという分野\n",
    "- 基本的枠組み\n",
    "    - エージェントと呼ばれるものが、環境状況に応じて行動を選択\n",
    "    - 選択した行動によって、環境が変化する\n",
    "    - 環境変化に伴ってエージェントは「報酬」を得る\n",
    "    - 良い報酬が得られるようにエージェントの行動指標を決める\n",
    "- 報酬について\n",
    "    - 報酬は決められたものではなく「**見込みの報酬**」\n",
    "    - どゆこと？\n",
    "        - マリオなら、右に動くことがどれだけの報酬に価するかは明確でない\n",
    "        - ゲームのスコア（コインを取った、敵を倒した）などゲームオーバーなどの明確な指標を逆算して、「見込み報酬」を決める\n",
    "- 手法:`Deep Q-Network（DQN）`\n",
    "    - Q学習と呼ばれる強化学習のアルゴリズムをベースとする手法\n",
    "        - Q学習：最適な行動を決定するために、`最適行動価値関数`とよばれる関数を決定\n",
    "    - 最適行動価値関数を近似するためにCNNを用いる\n",
    "    - ）テレビゲームコントロール\n",
    "        - 入力：ゲーム画像のフレーム（4つの連続したフレーム）\n",
    "        - 出力：コントローラーのそれぞれの動作に対する\"価値\"\n",
    "        - 単に**ゲームの画面だけ**を入力すれば良い。\n",
    "            - つまり、ジャンルの違うゲームにも対応できる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35180747",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
